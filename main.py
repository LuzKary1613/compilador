tabla = {#DICCIONARIO DE LA TABLA DE TRANSICIÓN
    0:  {'letra': 7,  'num': 3,  'noSigma': 59, 'EOF': 59, '+': 32, '-': 2,  '*': 33, '/': 34, '<': 13, '=': 31, '>': 14, ':': 12, ';': 35, ',': 36, '\'': 1,  '.': 37, '_': 6,  '[': 38, ']': 39, '{': 8,  '}': 40, '(': 9,  ')': 41, '\n': 0,  '\r': 0,  'space': 0},
    1:  {'letra': 1,  'num': 1,  'noSigma': 1,  'EOF': 43, '+': 1,  '-': 1,  '*': 1,  '/': 1,  '<': 1,  '=': 1,  '>': 1,  ':': 1,  ';': 1,  ',': 1,  '\'': 15, '.': 1,  '_': 1,  '[': 1,  ']': 1,  '{': 1,  '}': 1,  '(': 1,  ')': 1,  '\n': 42, '\r': 42, 'space': 1},
    2:  {'letra': 16, 'num': 3,  'noSigma': 44, 'EOF': 44, '+': 16, '-': 16, '*': 16, '/': 16, '<': 16, '=': 16, '>': 16, ':': 16, ';': 16, ',': 16, '\'': 16, '.': 16, '_': 16, '[': 16, ']': 16, '{': 16, '}': 16, '(': 16, ')': 16, '\n': 16, '\r': 16, 'space': 16},
    3:  {'letra': 17, 'num': 3,  'noSigma': 45, 'EOF': 45, '+': 17, '-': 17, '*': 17, '/': 17, '<': 17, '=': 17, '>': 17, ':': 17, ';': 17, ',': 17, '\'': 17, '.': 4,  '_': 17, '[': 17, ']': 17, '{': 17, '}': 17, '(': 17, ')': 17, '\n': 17, '\r': 17, 'space': 17},
    4:  {'letra': 47, 'num': 5,  'noSigma': 46, 'EOF': 46, '+': 47, '-': 47, '*': 47, '/': 47, '<': 47, '=': 47, '>': 47, ':': 47, ';': 47, ',': 47, '\'': 47, '.': 18, '_': 47, '[': 47, ']': 47, '{': 47, '}': 47, '(': 47, ')': 47, '\n': 47, '\r': 47, 'space': 47},
    5:  {'letra': 19, 'num': 5,  'noSigma': 48, 'EOF': 48, '+': 19, '-': 19, '*': 19, '/': 19, '<': 19, '=': 19, '>': 19, ':': 19, ';': 19, ',': 19, '\'': 19, '.': 19, '_': 19, '[': 19, ']': 19, '{': 19, '}': 19, '(': 19, ')': 19, '\n': 19, '\r': 19, 'space': 19},
    6:  {'letra': 7,  'num': 7,  'noSigma': 49, 'EOF': 49, '+': 49, '-': 49, '*': 49, '/': 49, '<': 49, '=': 49, '>': 49, ':': 49, ';': 49, ',': 49, '\'': 49, '.': 49, '_': 49, '[': 49, ']': 49, '{': 49, '}': 49, '(': 49, ')': 49, '\n': 49, '\r': 49, 'space': 49},
    7:  {'letra': 7,  'num': 7,  'noSigma': 50, 'EOF': 50, '+': 20, '-': 20, '*': 20, '/': 20, '<': 20, '=': 20, '>': 20, ':': 20, ';': 20, ',': 20, '\'': 20, '.': 20, '_': 7,  '[': 20, ']': 20, '{': 20, '}': 20, '(': 20, ')': 20, '\n': 20, '\r': 20, 'space': 20},
    8:  {'letra': 8,  'num': 8,  'noSigma': 8,  'EOF': 52, '+': 8,  '-': 8,  '*': 8,  '/': 8,  '<': 8,  '=': 8,  '>': 8,  ':': 8,  ';': 8,  ',': 8,  '\'': 8,  '.': 8,  '_': 8,  '[': 8,  ']': 8,  '{': 51, '}': 21, '(': 51, ')': 8,  '\n': 51, '\r': 51, 'space': 8},
    9:  {'letra': 22, 'num': 22, 'noSigma': 53, 'EOF': 53, '+': 22, '-': 22, '*': 10, '/': 22, '<': 22, '=': 22, '>': 22, ':': 22, ';': 22, ',': 22, '\'': 22, '.': 22, '_': 22, '[': 22, ']': 22, '{': 22, '}': 22, '(': 22, ')': 22, '\n': 22, '\r': 22, 'space': 22},
    10: {'letra': 10, 'num': 10, 'noSigma': 10, 'EOF': 54, '+': 10, '-': 10, '*': 11, '/': 10, '<': 10, '=': 10, '>': 10, ':': 10, ';': 10, ',': 10, '\'': 10, '.': 10, '_': 10, '[': 10, ']': 10, '{': 10, '}': 10, '(': 10, ')': 10, '\n': 10, '\r': 10, 'space': 10},
    11: {'letra': 10, 'num': 10, 'noSigma': 10, 'EOF': 55, '+': 10, '-': 10, '*': 10, '/': 10, '<': 10, '=': 10, '>': 10, ':': 10, ';': 10, ',': 10, '\'': 10, '.': 10, '_': 10, '[': 10, ']': 10, '{': 10, '}': 10, '(': 10, ')': 23, '\n': 10, '\r': 10, 'space': 10},
    12: {'letra': 25, 'num': 25, 'noSigma': 59, 'EOF': 56, '+': 25, '-': 25, '*': 25, '/': 25, '<': 25, '=': 24, '>': 25, ':': 25, ';': 25, ',': 25, '\'': 25, '.': 25, '_': 25, '[': 25, ']': 25, '{': 25, '}': 25, '(': 25, ')': 25, '\n': 25, '\r': 25, 'space': 25},
    13: {'letra': 28, 'num': 28, 'noSigma': 57, 'EOF': 57, '+': 28, '-': 28, '*': 28, '/': 28, '<': 28, '=': 27, '>': 26, ':': 28, ';': 28, ',': 28, '\'': 28, '.': 28, '_': 28, '[': 28, ']': 28, '{': 28, '}': 28, '(': 28, ')': 28, '\n': 28, '\r': 28, 'space': 28},
    14: {'letra': 30, 'num': 30, 'noSigma': 58, 'EOF': 58, '+': 30, '-': 30, '*': 30, '/': 30, '<': 30, '=': 29, '>': 30, ':': 30, ';': 30, ',': 30, '\'': 30, '.': 30, '_': 30, '[': 30, ']': 30, '{': 30, '}': 30, '(': 30, ')': 30, '\n': 30, '\r': 30, 'space': 30},
    15: 'string',
    16: '-',
    17: 'numEntero',
    18: '..',
    19: 'numDecimal',
    20: 'identifier',
    21: 'comments one line',
    22: '(',
    23: 'comments multi line',
    24: ':=', 
    25: ':',
    26: '<>', 
    27: '<=', 
    28: '<',
    29: '>=',
    30: '>',
    31: '=',
    32: '+',
    33: '*',
    34: '/',
    35: ';',
    36: ',',
    37: '.',
    38: '[',
    39: ']',
    40: '}',
    41: ')',
    42: 'ERROR: Por \n,\r ',
    43: 'ERROR: EOF ',
    44: 'ERROR: EOF, noSigma',
    45: 'ERROR: EOF, noSigma',
    46: 'ERROR: EOF, noSigma',
    47: 'ERROR: sigma - . - num',
    48: 'ERROR: EOF, noSigma',
    49: 'ERROR: EOF, noSigma, \n,\r, space, sigma',
    50: 'ERROR: EOF, noSigma',
    51: 'ERROR: {,(,\n,\r',
    52: 'ERROR: EOF',
    53: 'ERROR: EOF, noSigma',
    54: 'ERROR: EOF',
    55: 'ERROR: EOF',
    56: 'ERROR: EOF, noSigma',
    57: 'ERROR: EOF, noSigma',
    58: 'ERROR: EOF, noSigma',
    59: 'ERROR: EOF, noSigma',
} 

tokID = { #DICCIONARIO DE LOS TOKENS
    "program": "1",
    "procedure": "2",
    "function": "3",
    "begin": "4",
    "end": "5",
    "var": "6",
    "integer": "7",
    "real": "8",
    "string": "9",
    "array": "10",
    "of": "11",
    "if": "12",
    "then": "13",
    "else": "14",
    "repeat": "15",
    "until": "16",
    "for": "17",
    "to": "18",
    "do": "19",
    "readLn": "20",
    "writeLn": "21",
    "+": "22",
    "-": "23",
    "*": "24",
    "/": "25",
    "<": "26",
    "<=": "27",
    ">": "28",
    ">=": "29",
    "=": "30",
    "<>": "31",
    ":=": "32",
    ":": "33",
    ";": "34",
    ",": "35",
    "'": "36",
    ".": "37",
    "(": "38",
    ")": "39",
    "[": "40",
    "]": "41",
    "{": "42",
    "}": "43",
    "identifier": "44",
    "comments one line": "45",
    "comments multi line": "46",
    "numDecimal": "47",
    "numEntero": "48",
    "..": "49", 
    " error" : "50" 
}

        # DICCIONARIOS PARA LAS TABLAS DE SÍMBOLOS
# Diccionario que almacena los identificadores 
tabla_de_simbolos_de_identificadores = {}
# Diccionario que almacena los números enteros
tabla_de_simbolos_de_numeros_enteros = {}
# Diccionario que almacena los números decimales
tabla_de_simbolos_de_numeros_decimales = {}
# Diccionario que almacena los strings
tabla_de_simbolos_de_strings = {}



        # FUNCIÓN CLASIFICADORA DE CARACTERES
def tipo(caracter):
    # Verifica si el caracter es alfabético, si lo es, retorna 'letra'
    if caracter.isalpha(): 
        return 'letra'
    # Verifica si el caracter es un dígito numérico, si lo es, retorna 'num'
    elif caracter.isdigit(): 
        return 'num'
    # Verifica si el caracter está en la siguiente lista de símbolos, si lo es, retorna 'caracter' 
    elif caracter in ['{', '}', ';', '(', ')', '*', '/', '+', '-', '.', ':', ',', '=', '<', '>', '!', '[', ']', '\'']: 
        return caracter
    # Verifica si el caracter es un espacio en blanco, si lo es, retorna 'space'
    elif caracter.isspace():
        return 'space'
    # Si el caracter no cumple con ninguno de los criterios anteriores, retorna 'noSigma'
    else:
        return 'noSigma'
    


                                    # (ACEPTOR Y ERROR) DECIDEN CUÁNDO UN LEXEMA HA FORMADO UN TOKEN COMPLETO O SE HA ENCONTRADO UN ERROR #


        # FUNCIÓN QUE DETERMINA SI UN ESTADO DADO ES UN ESTADO DE ACEPTACIÓN
# Recibe el parámetro estado (estado actual en la máquina de estados)
def aceptor(estado):
    # Comprueba si el estado actual está dentro del rango de 15 a 41 
    return 15 <= estado <= 41
    # Devuelve True si el estado actual está dentro de este rango, de lo contrario, devuelve False




        # FUNCIÓN QUE DETERMINA SI UN ESTADO DADO ES UN ESTADO DE ACEPTACIÓN
# Recibe el parámetro estado (estado actual en la máquina de estados)
def error(estado):
    # Comprueba si el estado actual está dentro del rango de 42 a 59 
    return 42 <= estado <= 59
    # Devuelve True si el estado actual está dentro de este rango, de lo contrario, devuelve False




        # FUNCIÓN QUE DETERMINA COMO Y CUANDO EL ANALIZADOR LEXICO DEBE AVANZAR 
# estado = Estado actual en la máquina de estados 
# caracter_actual = Caracter que está siendo analizado actualmente
# caracter_siguiente = Próximo caracter en la entrada, que el analizador considerará después del actual
# tipo_caracter_actual = caracter_actual + tipo
# tipo_caracter_siguiente = caracter_actual + tipo
def avanzar(estado, caracter_actual, caracter_siguiente, tipo_caracter_actual, tipo_caracter_siguiente):
    # Conjunto de símbolos que requieren pausas en el análisis debido a su importancia en la sintaxis del lenguaje de programación
    simbolos = {';', '+', '-', '*', '/', '<', '>', '=', ':', '.', '\'', ',', '(', ')', '>=', '<=', '<>', ':='}
    # Verificar condiciones de avance basadas en el estado de aceptación o error
    if aceptor(estado):
        # Si el caracter_actual es un espacio o el caracter_siguiente es uno de los símbolos definidos o un espacio, retorna True
        if tipo_caracter_actual == 'space' or tipo_caracter_siguiente in simbolos or tipo_caracter_siguiente == 'space':
            # Se debe avanzar y potencialmente finalizar el token actual
            return True 
        # Si el caracter_actual está en el conjunto de símbolos, retorna True
        elif caracter_actual in simbolos:
            # Esto asegura que símbolos que pueden actuar como delimitadores de tokens sean procesados de manera inmediata
            return True
        # En otros casos, retorna False
        else:
            # Indica que aún no es momento de avanzar porque el lexema actual no está completo o no requiere pausa
            return False
    # Si el estado es un estado de error, la función siempre retorna False
    elif error(estado):
        return False
    # Avance por defecto
    else:
        # Si no se cumple ninguna de las condiciones anteriores, la función retorna True, permitiendo que el análisis continúe 
        return True
    



        # FUNCIÓN PARA AGREGAR ENTRADAS A LA TABLA DE SÍMBOLOS
# tabla_de_simbolos = Diccionario que representa la tabla de símbolos
# elemento = Lo se desea añadir a la tabla de símbolos
def agrega_a_tabla_de_simbolo(tabla_de_simbolos, elemento):
    # Se verifica si elemento ya existe en la tabla de símbolos
    # EL NOT IN EVITA DUPLICADOS EN LA TABLA DE SÍMBOLOS
    if elemento not in tabla_de_simbolos:
        # Si elemento no se encuentra en la tabla de símbolos, se añade al diccionario con un valor que corresponde al número total de elementos ya presentes en el diccionario más uno
        # El +1 incrementa el valor del índice de la tabla
        # len(table) devuelve el número de pares clave-valor presentes en el diccionario table por ejemplo 1 , 3.14
        tabla_de_simbolos[elemento] = len(tabla_de_simbolos) + 1
        



# FUNCIÓN QUE DETERMINA EL TOKEN APROPIADO BASADO EN EL ESTADO ACTUAL DE LA MAQUINA DE ESTADOS
# estado = estado actual del analizador
# lexema = cadena de caracteres (texto) que ha sido identificada como una unidad coherente (identificador, comentario, string, etc)
def obtener_token(estado, lexema):
    # Diccionario para mapear estados numéricos específicos a tokens deseados
    estado_a_token = {
        21: '45', # Token para comentario simple
        23: '46', # Token para comentario múltiple
        15: '9', # Token para string
        20: '44', # Token para identificador
        17: '48', # Token para números enteros
        19: '47', # Token para números con decimal
        16: '23', # Token -
        18: '49', # Token ..
        22: '38', # Token (
        24: '32', # Token :=
        25: '33', # Token :
        26: '31', # Token <>
        27: '27', # Token <=
        28: '26', # Token <
        29: '29', # Token >=
        30: '28', # Token >
        31: '30', # Token =
        32: '22', # Token +
        33: '24', # Token *
        34: '25', # Token /
        35: '34', # Token ;
        36: '35', # Token ,
        37: '37', # Token .
        38: '40', # Token [
        39: '41', # Token ]
        40: '43', # Token }
        41: '39', # Token )  
        42: '50', # ERROR: Por \n,\r 
        43: '50', # ERROR: EOF 
        44: '50', # ERROR: EOF, noSigma
        45: '50', # ERROR: EOF, noSigma
        46: '50', # ERROR: EOF, noSigma
        47: '50', # ERROR: sigma - . - num
        48: '50', # ERROR: EOF, noSigma
        49: '50', # ERROR: EOF, noSigma, \n,\r, space, sigma
        50: '50', # ERROR: EOF, noSigma
        51: '50', # ERROR: Por \n,\r, {,(
        52: '50', # ERROR: EOF 
        53: '50', # ERROR: EOF, noSigma
        54: '50', # ERROR: EOF 
        55: '50', # ERROR: EOF 
        56: '50', # ERROR: EOF, noSigma
        57: '50', # ERROR: EOF, noSigma
        58: '50', # ERROR: EOF, noSigma
        59: '50', # ERROR: EOF, noSigma
    }
    # Se verifica si el lexema es una palabra reservada consultando el diccionario tokID
    if lexema in tokID:
        #  Si el lexema es una palabra reservada, la función devuelve el token del diccionario tokID
        return tokID[lexema]
    # si el lexema no es una palabra reservada, verifica si el estado actual de la máquina de estados tiene un token guardado en el diccionario estado_a_token.
    if estado in estado_a_token:
        # Si el estado tiene un token en estado_a_token, se asigna ese token a la variable token
        token = estado_a_token[estado]
# ESTA PARTE SE PONE AQUÍ POR OPTIMIZACIÓN: SE TOMA EL TOKEN Y SE DECIDE QUE HACER CON EL, SI LLEGA ERROR, NO SE CREA LA TABLA DE SÍMBOLOS
# VERIFICACIÓN Y ACTUALIZACIÓN A LAS TABLAS DE SÍMBOLOS   
        # Si el estado indica que el lexema es un identificador, se añade a tabla_de_simbolos_de_identificadores
        if estado == 20:  #En tabla, identifier = 20
            agrega_a_tabla_de_simbolo(tabla_de_simbolos_de_identificadores, lexema)
        # Si el estado indica que el lexema es un número entero, se añade a tabla_de_simbolos_de_numeros_enteros
        elif estado == 17:  #En tabla, numEntero = 17
            agrega_a_tabla_de_simbolo(tabla_de_simbolos_de_numeros_enteros, lexema)
        # Si el estado indica que el lexema es un número decimal, se añade a tabla_de_simbolos_de_numeros_decimales
        elif estado == 19:  #En tabla, numDecimal = 19
            agrega_a_tabla_de_simbolo(tabla_de_simbolos_de_numeros_decimales, lexema)
        # Si el estado indica que el lexema es un string, se añade a tabla_de_simbolos_de_strings
        elif estado == 15: #En tabla, string = 15
            agrega_a_tabla_de_simbolo(tabla_de_simbolos_de_strings, lexema)
        #  Después de determinar el token y actualizar la tabla de símbolos correspondiente, se devuelve el token
        return token
    # Si el estado no corresponde a ningún token conocido y no es una palabra reservada, se devuelve "Token desconocido"
    return "Token desconocido"  # Si el estado no tiene mapeo y no es reservado




# FUNCIÓN QUE PROCESA EL TEXTO Y ASEGURA QUE LOS SÍMBOLOS ESTEN CORRECTAMENTE SEPARADOS POR ESPACIOS DE LOS OTROS ELEMENTOS
# texto = Cadena de caracteres que contiene el código fuente que se está analizando
def separar_simbolos(texto):
    # Define un conjunto de caracteres de símbolos
    simbolos = set([';', '(', ')', '*', '/', '+', '-', ':', ',', '=', '<', '>', '[', ']', '{', '}'])
    # Almacena el nuevo texto con los espacios adecuados insertados alrededor de los símbolos
    nuevo_texto = ""
    # Almacena la longitud del texto original para controlar el bucle de procesamiento.
    longitud = len(texto)
    # Inicializa un contador i en 0
    i = 0
    # Mientras el índice (i) sea menor que la longitud total del texto. (SE RECORREN TODOS LOS CARACTERES)
    while i < longitud:
#COMENTARIO DE UNA LINEA
        # Si el caracter actual es igual al { indica el inicio de un comentario de una linea
        if texto[i] == '{':
            # Mientras indice sea menor que la longitud total del texto y texto sea diferente a }
            while i < longitud and texto[i] != '}':
                # Agrega cada carácter del comentario a nuevo_texto
                nuevo_texto += texto[i]
                # Incremento del índice i para avanzar al siguiente carácter en el texto
                i += 1
            if i < longitud:  # Asegura incluir el símbolo '}'
                # Añade el carácter } al nuevo_texto y avanza el índice. (ES IMPORTANTE PORQUE CUANDO DETECTA } SE DETIENE)
                nuevo_texto += texto[i]
                # Incremento del índice i para avanzar al siguiente carácter en el texto
                i += 1
            # Se salta al inicio del bucle
            continue
# COMENTARIO DE VARIAS LINEAS
        # Si el caracter actual es igual al (, el indice es menor a la longitud total del texto y el siguiente caracter es un * indica el inicio de un comentario de varias lineas
        elif texto[i] == '(' and i + 1 < longitud and texto[i+1] == '*':
            # Agrega el carácter de apertura del comentario al nuevo_texto
            # Añade el carácter ( al nuevo_texto y avanza el índice. (ES IMPORTANTE PORQUE CUANDO DETECTA ( SE DETIENE)
            nuevo_texto += texto[i]  
            # Incremento del índice i para avanzar al siguiente carácter en el texto
            i += 1
            # Añade el carácter * al nuevo_texto y avanza el índice. (ES IMPORTANTE PORQUE CUANDO DETECTA * SE DETIENE)
            nuevo_texto += texto[i]  
            # Incremento del índice i para avanzar al siguiente carácter en el texto
            i += 1
            # Mientras el indice sea menor a la longitud total del texto y el caracter no sea *)
            while i < longitud and not (texto[i] == '*' and i + 1 < longitud and texto[i+1] == ')'):
                # Añade el carácter ( al nuevo_texto y avanza el índice. (ES IMPORTANTE PORQUE CUANDO DETECTA ( SE DETIENE)
                nuevo_texto += texto[i]
                # Incremento del índice i para avanzar al siguiente carácter en el texto
                i += 1
            # Si el indice es menor a la longitud total del texto
            if i < longitud:
                # Añade el carácter * al nuevo_texto y avanza el índice. (ES IMPORTANTE PORQUE CUANDO DETECTA * SE DETIENE)
                nuevo_texto += texto[i]  
                # Incremento del índice i para avanzar al siguiente carácter en el texto
                i += 1
            # Si el indice es menor a la longitud total del texto
            if i < longitud:
                # Añade el carácter ) al nuevo_texto y avanza el índice. (ES IMPORTANTE PORQUE CUANDO DETECTA * SE DETIENE)
                nuevo_texto += texto[i]  
                # Incremento del índice i para avanzar al siguiente carácter en el texto
                i += 1
            # Se salta al inicio del bucle
            continue
# NÚMEROS ENTEROS Y REALES
        # Si el caracter actual es un digito o un punto decimal y el indice es menor a la longitud total del texto y el siguiente caracter es un número (3.2)
        elif texto[i].isdigit() or (texto[i] == '.' and i + 1 < longitud and texto[i+1].isdigit()):
            # Guarda la posición inicial del número 
            start = i
            # Mientras el indice sea menor a la longitud total del texto y el caracter actual sea un número o un . y el siguiente caracter sea un número
            while i < longitud and (texto[i].isdigit() or (texto[i] == '.' and i + 1 < longitud and texto[i+1].isdigit())):
                # # Agrega cada carácter del comentario a nuevo_texto
                nuevo_texto += texto[i]
                # # Incremento del índice i para avanzar al siguiente carácter en el texto
                i += 1
            # Si el texto termina en .
            if texto[i-1] == '.':
                # Si el último carácter es un punto y el siguiente carácter no es un espacio, un dígito, o un símbolo
                if i < longitud and not texto[i].isspace() and not (texto[i].isdigit() or texto[i] in simbolos):
                    # Se añade un espacio al nuevo_texto
                    nuevo_texto += ' '
            # Si el último carácter no es un punto pero se cumplen condiciones similares, también se añade un espacio para separar el número de cualquier texto o símbolo
            else:
                # Si el último carácter es un punto y el siguiente carácter no es un espacio, un dígito, o un símbolo
                if i < longitud and not texto[i].isspace() and not (texto[i].isdigit() or texto[i] in simbolos):
                    # Se añade un espacio al nuevo_texto
                    nuevo_texto += ' '
            # Se salta al inicio del bucle
            continue
# PUNTO A LADO DE CUALQUIER COSA MENOS NÚMERO
        # Si el caracter actual es un punto y el punto esta al inicio o el caracter anterior no es un número y el punto está al final del texto o el carácter siguiente no es un número
        elif texto[i] == '.' and (i == 0 or not texto[i-1].isdigit()) and (i == longitud - 1 or not texto[i+1].isdigit()):
            # Si el punto no está al principio y el carácter anterior no es un espacio:
            if i > 0 and not texto[i-1].isspace():
                # 1 - se inserta un espacio antes del punto
                nuevo_texto += ' '
            # Se añade el punto al nuevo_texto.
            nuevo_texto += texto[i]
            # Si el punto no está al final y el carácter siguiente no es un espacio:
            if i < longitud - 1 and not texto[i+1].isspace():
                # 1 - Se inserta un espacio después del punto
                nuevo_texto += ' '
# OTROS SÍMBOLOS
        # Si el carácter actual está dentro del conjunto de símbolos definidos 
        elif texto[i] in simbolos:
            # Si el carácter anterior no es un símbolo o un espacio: 
            if i > 0 and texto[i-1] not in simbolos and not texto[i-1].isspace():
                # 1- Se añade un espacio antes del símbolo actual
                nuevo_texto += ' '
            # Añade el símbolo al nuevo_texto
            nuevo_texto += texto[i]
            # Si el carácter siguiente no es un símbolo y no es un espacio: 
            if i < longitud - 1 and texto[i+1] not in simbolos and not texto[i+1].isspace():
                # 1 - Se añade un espacio después del símbolo
                nuevo_texto += ' '
        # Si el carácter actual no es un punto que funcione como separador y no es uno de los símbolos especiales: 
        else:
            # Simplemente se añade al nuevo_texto como está
            nuevo_texto += texto[i]
        # Se incrementa el índice i después de procesar cada carácter para moverse al siguiente en el texto
        i += 1
    # Una vez finalizado el bucle y procesado todo el texto, la función retorna el nuevo_texto modificado, que ahora tiene todos los símbolos y puntos adecuadamente espaciados
    return nuevo_texto





# FUNCIÓN QUE CONVIERTE EL TEXTO DE ENTRADA EN UNA LISTA DE TOKENS
def escanear(texto):
    # Antes de iniciar el escaneo, se procesa el texto para asegurar que los símbolos estén correctamente separados por espacios
    texto = separar_simbolos(texto)
    # Lista vacía para almacenar los tokens identificados
    tokens = []
    # Variable para mantener el estado actual de la máquina de estados
    estado = 0
    # Cadena vacía para acumular caracteres que forman un lexema
    lexema = ''
    # Índice para recorrer cada caracter del texto.
    indice = 0
    # Se añade un caracter especial (EOF, fin de archivo) al final del texto para marcar su término y facilitar la detección del final durante el escaneo
    texto += '\0'  
    # Recorre el texto caracter por caracter hasta que el índice alcanza el penúltimo caracter
    while indice < len(texto) - 1:
        # caracter_actual se establece al caracter en la posición actual del índice dentro del texto
        caracter_actual = texto[indice]
        # Se verifica que el indice + 1 sea menor que la longitud total del texto. Si indice + 1 es igual o supera la longitud del texto, caracter_siguiente se establece a None
        caracter_siguiente = texto[indice + 1] if indice + 1 < len(texto) else None
        # Esta línea llama a la función tipo(), pasándole el caracter_actual. Esta función clasifica el caracter según su tipo
        tipo_caracter_actual = tipo(caracter_actual)
        # Esta línea determina el tipo de caracter_siguiente, pero solo si caracter_siguiente no es None. Si es None, tipo_caracter_siguiente se establece a None
        tipo_caracter_siguiente = tipo(caracter_siguiente) if caracter_siguiente else None
        # Se verifica si el tipo del caracter_actual es válido para el estado actual según la tabla de transiciones (tabla)
        if tipo_caracter_actual in tabla[estado]:
            # Si el tipo del caracter_actual es válido para el estado actual, se determina el estado_siguiente usando la tabla de transiciones
            estado_siguiente = tabla[estado][tipo_caracter_actual]
            # Se llama a la función avanzar() para decidir si se debe continuar añadiendo caracteres al lexema actual o comenzar un nuevo lexema
            if avanzar(estado, caracter_actual, caracter_siguiente, tipo_caracter_actual, tipo_caracter_siguiente):
                #ACOMULACIÓN DEL LEXEMA: Si se decide avanzar, se añade el caracter_actual al lexema actual
                lexema += caracter_actual
                # Si el estado_siguiente es un estado de aceptación, se procesa el lexema para formar un token
                if aceptor(estado_siguiente):
                    # Si hay un lexema no vacío después de retirar espacios:  
                    if lexema.strip():
                        token = obtener_token(estado_siguiente, lexema.strip()) # 1 - se obtiene el token usando obtener_token()
                        tokens.append((token, lexema.strip())) # 2 - y se añade a la lista de tokens
                    # Después de procesar un token:  
                    lexema = '' # 1 - se limpia lexema
                    estado = 0 # 2 - se reinicia el estado a 0 para empezar a procesar un nuevo lexema
                # Si el estado_siguiente es un estado de error:   
                elif error(estado_siguiente):
                    print(f"Error en el índice: {indice} en el estado: {estado_siguiente}, con lexema: '{lexema}'") # 1 - se imprime un mensaje de error 
                    lexema = '' # 2 - se limpia lexema
                    estado = 0 # 3 - se reinicia el estado a 0 para empezar a procesar un nuevo lexema
                # Si no es un estado de aceptación ni de error: 
                else:
                    # se actualiza el estado al estado_siguiente para seguir procesando más caracteres bajo las nuevas condiciones
                    estado = estado_siguiente
# MANTIENE LA CONTINUIDAD DEL LEXEMA
            # Este else se ejecuta cuando la función avanzar() determina que no se debe avanzar al próximo caracter, es decir, que el caracter_actual debería seguir formando parte del lexema actual
            else:
                # caracter_actual se añade al lexema actual
                lexema += caracter_actual
# MANEJO DE CARACTERES NO ENCONTRADOS
        else:
            # Se imprime un mensaje indicando que el caracter actual no fue encontrado en la tabla para el estado dado
            print(f"No encontrado en el índice: {indice}, con caracter: '{caracter_actual}'")
            # Antes de desechar el contenido del lexema actual y reiniciar, se verifica si el lexema contiene algún texto significativo
            if lexema.strip():
                # Si hay contenido válido, se llama a la función obtener_token(estado, lexema.strip()) para intentar obtener un token basado en el estado actual y el contenido del lexema
                token = obtener_token(estado, lexema.strip())
                # Si se obtiene un token, este se añade junto con el lexema limpio a la lista tokens y :
                tokens.append((token, lexema.strip()))
            lexema = '' # 1 - se limpia lexema
            estado = 0  # 2 - se reinicia el estado a 0 para empezar a procesar un nuevo lexema
        # Se incrementa el indice para continuar el análisis con el siguiente caracter en el texto
        indice += 1
# MANEJO DE CARACTERES QUE SE QUEDARON PENDIENTES AL FINAL DEL ANÁLISIS
    # Verifica si hay un lexema restante que contenga caracteres distintos de espacios en blanco al final del proceso de análisis
    if lexema.strip():
        # Llama a la función obtener_token() para convertir el lexema final en un token.
        token = obtener_token(estado, lexema.strip())
        # Añade el token y el lexema limpio a la lista tokens
        tokens.append((token, lexema.strip()))
    # Después de asegurarse de que todos los lexemas han sido procesados y convertidos en tokens, la función escanear() retorna la lista tokens
    return tokens



# Función: El método .strip() en Python es utilizado para remover los espacios en blanco al principio y al final de un string
    # Limpiar los lexemas de espacios innecesarios antes de convertirlos en tokens y antes de almacenarlos
        # Ejemplo de Uso: lexema.strip() se usa para asegurar que el lexema procesado no tenga espacios extras que podrían haberse incluido durante el análisis

# Función: El método .append() en Python es usado para añadir un elemento al final de una lista. Este método modifica la lista original y no retorna ningún valor
    # Agrega los tokens procesados y sus lexemas asociados a la lista tokens
        # Ejemplo de Uso: tokens.append((token, lexema.strip())) añade una tupla que contiene el token y el lexema asociado (ya limpio de espacios extra) a la lista de tokens




# FUNCIÓN PARA IMPRIMIR LA TABLA DE SÍMBOLOS
def imprimir_tabla_de_simbolos():
    print(" ") # ESPACIO
    print(" ") # ESPACIO
    print(" ") # ESPACIO
    print("TABLA DE SIMBOLOS")
    print(" ") # ESPACIO
    # MENSAJE
    print("1) IDENTIFICADORES:")
    # .items() = Método que devuelve una vista de los pares clave-valor del diccionario (Identificador, Indice)
    for identificador, indice in tabla_de_simbolos_de_identificadores.items():
        # IMPRIME EL INDICE Y EL NÚMERO DECIMAL
        print(f"INDICE {indice}: {identificador}")
    # MENSAJE
    print(" ") # ESPACIO
    print("2) NUMEROS ENTEROS:")
    # .items() = Método que devuelve una vista de los pares clave-valor del diccionario (numEntero, Indice)
    for numEntero, indice in tabla_de_simbolos_de_numeros_enteros.items():
        # IMPRIME EL INDICE Y EL NÚMERO DECIMAL
        print(f"INDICE {indice}: {numEntero}")
    # MENSAJE
    print(" ") # ESPACIO
    print("3) NUMEROS DECIMALES:")
    # .items() = Método que devuelve una vista de los pares clave-valor del diccionario (numDecimal, Indice)
    for numDecimal, indice in tabla_de_simbolos_de_numeros_decimales.items():
        # IMPRIME EL INDICE Y EL NÚMERO DECIMAL
        print(f"INDICE {indice}: {numDecimal}")
    # MENSAJE
    print(" ") # ESPACIO
    print("4) STRINGS:")
    # .items() = Método que devuelve una vista de los pares clave-valor del diccionario (string, Indice)
    for string, indice in tabla_de_simbolos_de_strings.items():
        print(f"INDICE {indice}: {string}")
     
      


# FUNCIÓN QUE IMPRIME EL TOKEN Y EL INDICE
# tupla = Lista de tuplas, donde cada tupla contiene un token y un lexema asociado
# .get(): Este método intenta obtener el lexema en la tabla correspondiente. Si el lexema no está presente, devuelve 'Sin índice'
def imprimir_tokens_con_indices(tupla):
    print(" ") # ESPACIO
    print(" ") # ESPACIO
    print(" ") # ESPACIO
    print("TOKENS E INDICES:")
    # Bucle que iterará sobre cada elemento en la lista tupla
    for token, lexema in tupla:
        # Se inicializa la variable indice en None, (para almacenar el índice del lexema si es encontrado en alguna tabla de símbolos)
        indice = None
        # Si token es igual a 47 "numDecimal"
        if token == '47':  
            # Busca el lexema en tabla_de_simbolos_de_numeros_decimales
            indice = tabla_de_simbolos_de_numeros_decimales.get(lexema, 'Sin índice')
        # Si token es igual a 48 "numEntero"
        elif token == '48':  
            # Busca el lexema en tabla_de_simbolos_de_numeros_enteros
            indice = tabla_de_simbolos_de_numeros_enteros.get(lexema, 'Sin índice')
        # Si token es igual a 44 "identifier"
        elif token == '44':  
            # Busca el lexema en tabla_de_simbolos_de_numeros_decimales
            indice = tabla_de_simbolos_de_identificadores.get(lexema, 'Sin índice')
        # Si token es igual a 9 "string"
        elif token == '9': 
            # Busca el lexema en tabla_de_simbolos_de_strings
            indice = tabla_de_simbolos_de_strings.get(lexema, 'Sin índice')
        # Si indice existe y es diferente de 'Sin índice': 
        if indice and indice != 'Sin índice':
            # 1- imprime el token y el indice
            print(f"{token}, {indice}")
        # Si indice no existe o es 'Sin índice'
        else:
            # 2- Solo imprime el token
            print(f"{token}, ")
            
            
# EJECUTA EL ESCANER EN EL TEXTO DE ENTRADA
texto_de_entrada = """ 
{ Example #1 }
{ This is the typical "Hello World" }
program HelloWorld;
(* This is the main program block *)
begin
writeLn( ' Hello World ' );
end. (* This is the end of the main
program block *)

"""


# escanear(): Esta función toma como entrada una cadena de texto 
# texto_de_entrada = Texto de prueba
# resultado: Recibe el valor devuelto por la función escanear()
resultado = escanear(texto_de_entrada)
# MENSAJE
print("TOKEN Y TEXTO:")
print(" ") # ESPACIO
# Bucle que recorre la lista resultado. En cada iteración, extrae una tupla que contiene dos elementos: token y lexema.
for token, lexema in resultado:
    print(f"{token}, {lexema}")
# IMPRESIÓN
imprimir_tabla_de_simbolos()
# IMPRESIÓN
imprimir_tokens_con_indices(resultado)
